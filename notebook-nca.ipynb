{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Neural Cellular Automata_v2.0.2.ipynb","provenance":[{"file_id":"17OBLoP2rTKANS6qDVeQVM4QxI9BHuRn6","timestamp":1595428349304},{"file_id":"1X08Me9CvYgi3a1gx8oCfU_OFiVn2ajWI","timestamp":1595181756605}],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"NQAwwoaJdFzb","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.nn import functional as F\n","from torch.optim.lr_scheduler import StepLR\n","\n","import os\n","import cv2\n","import uuid\n","import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","def save_model():\n","    return \"\"\n","\n","def load_model(model, weight_folder):\n","    model.load_state_dict(torch.load(weight_folder))\n","    model.eval()\n","    return \"Model loaded.\"\n","\n","# CUDA\n","def check_cuda():\n","    if not torch.cuda.is_available():\n","        device = torch.device('cpu')\n","    else:\n","        device = torch.device(\"cuda:0\")\n","\n","    return device\n","\n","device = check_cuda()\n","\n","# GENERATE RANDOM ID\n","def gen_id():\n","    return str(uuid.uuid4().fields[-1])[:6]\n","\n","# GENERATE X\n","def call_grid(size):\n","    x = torch.zeros(size).type(torch.float32)\n","    b, c, h, w = size\n","    x[:, 3:, h // 2, w // 2] = 1.0\n","    return x\n","\n","# SOBEL CLASS\n","class Sobels():\n","    def sobels(self):\n","        identify = torch.tensor([[ 0,0,0],[0,1,0], [0,0,0]])\n","        dx = torch.tensor([[-1,0,1],[-2,0,2],[-1,0,1]])\n","        dy = torch.tensor([[ 1,2,1],[0,0,0], [-1,-2,-1]])\n","        return identify, dx, dy\n","\n","    def batch_sobels(self, n_channel):\n","        self.n_channel = n_channel\n","        i, x, y = self.sobels()\n","        identify = i.repeat(self.n_channel, 1, 1, 1).type(torch.float32).to(device)\n","        dx = x.repeat(self.n_channel, 1, 1, 1).type(torch.float32).to(device)\n","        dy = y.repeat(self.n_channel, 1, 1, 1).type(torch.float32).to(device)\n","\n","        return identify, dx, dy\n","    \n","    def __len__(self):\n","        return len(self.sobels())\n","\n","# CREATE PERCEPTION\n","def perception(x):\n","    b,c,h,w = x.size()\n","    sobels = Sobels(c)\n","    sobel_I, sobel_X, sobel_Y = Sobels.get(c)\n","    c_sobel_I = F.conv2d(x, sobel_I, padding=1, groups=c)\n","    c_sobel_X = F.conv2d(x, sobel_X, padding=1, groups=c)\n","    c_sobel_Y = F.conv2d(x, sobel_Y, padding=1, groups=c)\n","    \n","    pv = torch.stack((c_sobel_I, c_sobel_X, c_sobel_Y)).type(torch.float32).view(b, n_filter*c, h, w) # view en lugar de shape ?\n","    return pv\n","\n","def perception_2(x):\n","    b,c,h,w = x.size()\n","    sobels = Sobels()\n","    sobel_I, sobel_X, sobel_Y = sobels.batch_sobels(c)\n","    filters = [sobel_I, sobel_X, sobel_Y]\n","    perception = torch.empty((b, len(filters) * c, h, w)).to(device)\n","\n","    # Computamos los vectores de percepciÃ³n con cada filtro. 3 filtros x 16 = 48 componentes.\n","    for f, filt in enumerate(filters):\n","        perception[:, (f * c):((f+1) * c), :, :] = F.conv2d(x, filt, groups=c, padding=[1, 1])\n","    return perception\n","\n","# GENERATE A STOCASTIC UPDATE\n","def stochastic_update(x, output):\n","    b,c,h,w = x.size()\n","    stochastic_matrix = torch.randint(0,2,((b,c,h,w))).to(device)  # 0 a 2 ?\n","    return stochastic_matrix\n","\n","# DETECT ALIVE CELLS \n","def detect_alives_cells(output):\n","    b,c,h,w = output.size()\n","    alive_filter = torch.ones((1,1,3,3)).type(torch.double).to(device)    # b = 1 ?\n","    alpha = (output[:,3:4,:,:] > 0.1).type(torch.double).to(device)\n","    alives = F.conv2d(alpha, alive_filter, padding=1)\n","    alives = (alives > 0.0)\n","    alives = alives.repeat(1, c, 1, 1)\n","    return alives\n","\n","# BATCH TARGET IMAGE\n","def batch_target(file_path, batch):\n","    #img = cv2.imread(file_path, -1) / 255.0\n","    img = np.array(Image.open(file_path)) / 255.\n","    target = torch.from_numpy(img)[None, :, :, :].permute(0,3,1,2).type(torch.float32).to(device)\n","    target = target.repeat(batch,1,1,1)\n","    return target\n","\n","# UNBATCH TENSOR   \n","def unbatch_tensor(x, default=\"Tensor\"):\n","    b, c, h, w = x.size()\n","    x = x.permute(0,2,3,1)\n","    x = x.detach().cpu().numpy()\n","    return x[0,:,:,:4]\n","\n","# PLOT A TENSOR\n","def plot_tensor(x, title, default=\"Tensor\"):\n","    if default == \"Tensor\":\n","        b, c, h, w = x.size()\n","        x = x.permute(0,2,3,1)\n","        x = x.detach().cpu().numpy()\n","        plt.title(str(title).upper())\n","        plt.imshow(x[0,:,:,:4])\n","\n","    elif default == \"Image\":\n","        img = cv2.imread(x, -1)\n","        plt.title(str(title).upper())\n","        plt.imshow(img)\n","\n","# DEBUG TENSOR MIN MAX \n","def tensorMinMax(x, name, debug):\n","    if debug:\n","        print(\"[{0}]\\tMin: {1}, Max: {2}\".format(name.capitalize(), x.min(), x.max()))\n","    else:\n","        pass\n","\n","\n","class NCA(nn.Module):\n","    def __init__(self, n_channel, n_filter):\n","        super(NCA, self).__init__()\n","        self.n_channel = n_channel\n","        self.n_filter = n_filter\n","        self.fc1 = nn.Conv2d((self.n_channel * self.n_filter), 128, (1,1))\n","        self.fc2 = nn.Conv2d(128, n_channel, (1,1))\n","        torch.nn.init.zeros_(self.fc2.weight)\n","        #torch.nn.init.zeros_(self.fc2.bias)\n","    \n","    def forward(self, x):\n","      b, c, h, w = x.size()\n","      \n","      #pVector = perception(x)  \n","      pVector = perception_2(x)  \n","      dx = self.fc1(pVector)\n","      dx = F.relu(dx) \n","      dx = self.fc2(dx)      \n","      \n","      #random_matrix = torch.from_numpy(np.random.randint(0, 2, (b, c, h, w))).to(device)\n","      random_matrix = stochastic_update(x, dx)\n","      x = x + random_matrix * dx\n","      alives = detect_alives_cells(x)        # Conv (3,3) > 0.1\n","\n","      return alives * x\n","\n","# HYPERPARAMETERS #\n","lr = 2e-3\n","epochs = 1001\n","r_seed = np.random.seed(24)             # Defining a default random seed.\n","n_steps = np.random.randint(64, 96)     # Number of step of each epoch\n","\n","# TENSOR FORMAT #\n","b = 8\n","h = 32\n","w = 32\n","n_channel = 16\n","n_filter = Sobels().__len__()           # Number of sobels configurated.\n","\n","# FOLDERS #\n","weights_folder = \"./weights\"\n","results_folder = \"./training_output\"\n","os.mkdir(results_folder) if not os.path.exists(results_folder) else \"\"\n","\n","# MODEL PARAMETERS # \n","L2 = nn.MSELoss()                       # MSE as loss function.\n","device = check_cuda()                   # Select CPU or CUDA if is available.\n","save_steps_time   = epochs // 3         # Save plots of growining steps 3 times during the training proccess.\n","save_outpus_time  = epochs // 10        # Save plots of final epoch 10 times during the training process.    \n","\n","# DEFINING MODEL \n","model = NCA(n_channel, n_filter).to(device)\n","optimizer = optim.Adam(model.parameters(), lr=lr)\n","scheduler = StepLR(optimizer, step_size=500, gamma=0.1)\n","\n","# DEFINING Y (TARGET IMAGE)\n","target_img = \"./input/cynda.png\"\n","target = batch_target(target_img, b).to(device)\n","\n","# TRAINING PROCESS\n","for epoch in range(epochs):\n","\n","  # DEFINING X OR GRID CELL    \n","  X = call_grid((b, n_channel, h, w)).to(device)\n","\n","  # STEP PROCESS\n","  for step in range(n_steps):\n","    X = model.forward(X)\n","    X = torch.clamp(X, 0, 1)\n","\n","    # EXPORTING: SEQUENCE OF GROWNING CELL\n","    if epoch % save_steps_time == 0:\n","          step_folder = \"steps_epoch_{}\".format(epoch)\n","          steps_folder = os.path.join(results_folder, step_folder)\n","          os.mkdir(steps_folder) if not os.path.exists(steps_folder) else \"\"\n","\n","          step_file = '{}_{}.png'.format(epoch, step, n_steps)\n","          step_path = os.path.join(steps_folder, step_file)\n","\n","          fig = plt.figure()\n","          plt.imshow(unbatch_tensor(X))\n","          plt.savefig(step_path, bbox_inches='tight', dpi=100)\n","          plt.close(fig)\n","\n","  # RUNNING PREDICTION      \n","  optimizer.zero_grad()\n","  X = torch.clamp(X, 0, 1)\n","  output = X[:, :4, :, :]\n","\n","  # CALCULATING LOSS\n","  loss = L2(output, target)\n","  print(\"Epoch {}/{} - Loss: {}\".format(epoch, epochs, str(loss.item())[0:6]))\n","\n","  # EXPORTING: PREDICTION IMAGE\n","  if epoch % save_outpus_time == 0:\n","\n","        fig = plt.figure()\n","        output_file = 'output_epoch_{}_loss_{}.png'.format(epoch, str(loss.item())[0:6])\n","        output_path = os.path.join(results_folder, output_file)\n","        plt.imshow(unbatch_tensor(output))\n","        plt.savefig(output_path, bbox_inches='tight', dpi=200)\n","        plt.close(fig)\n","\n","  # OPTIMIZING PROCESS\n","  loss.backward()\n","  optimizer.step()\n","  scheduler.step()\n","\n","# SAVING TRAINING\n","uid = gen_id()\n","weight_file = \"nca-{}_epoch{}_loss{}.path\".format(uid, epochs, str(loss.item())[0:6])\n","\n","weights_path = os.path.join(weights_folder, weight_file)\n","torch.save(model.state_dict(), weights_path)\n","print(\"Model Saved.\")"],"execution_count":null,"outputs":[]}]}